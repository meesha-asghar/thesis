{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import display \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,  AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_pickle(r'data\\data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = dt.groupby('activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just keep 4 activities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = ['standing', 'walking','running','cycling']\n",
    "data = dt.loc[dt['activity'].isin(vals)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walking     229709\n",
       "standing    188984\n",
       "cycling     163302\n",
       "running      95641\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.activity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut off first and last 1000 items, because activity starts end ends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data.activity=='running'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='running'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='walking'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='walking'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='cycling'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='cycling'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='standing'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='standing'].iloc[-1000:].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walking     227709\n",
       "standing    186984\n",
       "cycling     161302\n",
       "running      93641\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.activity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Acceleration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "absolute acceleration: $|a|=\\sqrt{a_x^2 + a_y^2 + a_z^2}$\n",
    "\n",
    "to get rid of the orientation of the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absacc(row):\n",
    "    return np.sqrt(row['IMU_chest_ax1']**2 + row['IMU_chest_ay1']**2 + row['IMU_chest_az1']**2)/9.806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['absacc'] = data.apply(absacc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Min Difference of absolute Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=512\n",
    "dt = 1.0/100.0 # the activities were with 50Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accmax'] =  data['absacc'].rolling(window=ws,center=False).max() \n",
    "data['accmin'] = data['absacc'].rolling(window=ws,center=False).min() \n",
    "\n",
    "data['accmaxmindiff'] = data.accmax - data.accmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform of Rotation Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_amplitude(s, kind='peak'):\n",
    "    \n",
    "    # don't forget the windowing to get rid of the leakage effect\n",
    "    hann = np.hanning(len(s)) \n",
    "    \n",
    "    # do the FFT with Hanning Window\n",
    "    Yhann = np.fft.fft(hann*s)\n",
    "    \n",
    "    N = int(len(Yhann)/2+1)\n",
    "    Y = 2*(np.abs(Yhann[:N])/N) # right half is enough info(positive freqs only)\n",
    "    \n",
    "    # frequency axis, if needed\n",
    "    fa = 1.0/dt\n",
    "    f = np.linspace(0, fa/2.0, N, endpoint=True)\n",
    "    \n",
    "    if kind=='peak':\n",
    "        return np.max(Y) # just return the maximum peak amplitude\n",
    "    elif kind=='periodicity':\n",
    "        return np.max(Y) / np.mean(Y) # return periodicity\n",
    "    elif kind=='full':\n",
    "        return f, Y # return the full spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fftamppeak'] = data['IMU_chest_rotz'].rolling(window=1*ws,center=False).apply(fft_amplitude, raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the rolling_ functions, there is overlap between the activity features and the labels, corresponding to it. We have to delete some rows (length of window), before using a classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data.activityID==3].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==4].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==5].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==6].iloc[0:int(ws)-1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activityID</th>\n",
       "      <th>activity</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>IMU_hand_temp</th>\n",
       "      <th>IMU_hand_ax1</th>\n",
       "      <th>IMU_hand_ay1</th>\n",
       "      <th>IMU_hand_az1</th>\n",
       "      <th>IMU_hand_ax2</th>\n",
       "      <th>IMU_hand_ay2</th>\n",
       "      <th>IMU_hand_az2</th>\n",
       "      <th>...</th>\n",
       "      <th>IMU_ankle_roty</th>\n",
       "      <th>IMU_ankle_rotz</th>\n",
       "      <th>IMU_ankle_magx</th>\n",
       "      <th>IMU_ankle_magy</th>\n",
       "      <th>IMU_ankle_magz</th>\n",
       "      <th>absacc</th>\n",
       "      <th>accmax</th>\n",
       "      <th>accmin</th>\n",
       "      <th>accmaxmindiff</th>\n",
       "      <th>fftamppeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55106</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.549558</td>\n",
       "      <td>7.35420</td>\n",
       "      <td>6.75881</td>\n",
       "      <td>0.484190</td>\n",
       "      <td>7.79716</td>\n",
       "      <td>6.62053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.053009</td>\n",
       "      <td>-88.223999</td>\n",
       "      <td>32.996899</td>\n",
       "      <td>-4.05403</td>\n",
       "      <td>1.003447</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55107</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.513651</td>\n",
       "      <td>6.86262</td>\n",
       "      <td>6.91388</td>\n",
       "      <td>0.588009</td>\n",
       "      <td>7.32850</td>\n",
       "      <td>6.89326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>-0.028382</td>\n",
       "      <td>-87.089302</td>\n",
       "      <td>32.827202</td>\n",
       "      <td>-2.57978</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55108</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.851353</td>\n",
       "      <td>6.70790</td>\n",
       "      <td>6.88097</td>\n",
       "      <td>0.707032</td>\n",
       "      <td>6.95026</td>\n",
       "      <td>7.09028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024165</td>\n",
       "      <td>-0.043116</td>\n",
       "      <td>-87.096298</td>\n",
       "      <td>32.838799</td>\n",
       "      <td>-3.44605</td>\n",
       "      <td>1.005541</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55109</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.765876</td>\n",
       "      <td>6.81962</td>\n",
       "      <td>6.57141</td>\n",
       "      <td>0.750087</td>\n",
       "      <td>6.72339</td>\n",
       "      <td>7.06053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>-0.037264</td>\n",
       "      <td>-87.545700</td>\n",
       "      <td>32.640499</td>\n",
       "      <td>-3.93960</td>\n",
       "      <td>1.002116</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55110</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.798051</td>\n",
       "      <td>6.78005</td>\n",
       "      <td>6.41808</td>\n",
       "      <td>0.853185</td>\n",
       "      <td>6.63185</td>\n",
       "      <td>6.86432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-87.654099</td>\n",
       "      <td>32.099201</td>\n",
       "      <td>-4.43960</td>\n",
       "      <td>1.003846</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activityID  activity  heartrate  IMU_hand_temp  IMU_hand_ax1  \\\n",
       "55106           3  standing        101        32.6875      0.549558   \n",
       "55107           3  standing        101        32.6875      0.513651   \n",
       "55108           3  standing        101        32.6875      0.851353   \n",
       "55109           3  standing        101        32.6875      0.765876   \n",
       "55110           3  standing        101        32.6875      0.798051   \n",
       "\n",
       "       IMU_hand_ay1  IMU_hand_az1  IMU_hand_ax2  IMU_hand_ay2  IMU_hand_az2  \\\n",
       "55106       7.35420       6.75881      0.484190       7.79716       6.62053   \n",
       "55107       6.86262       6.91388      0.588009       7.32850       6.89326   \n",
       "55108       6.70790       6.88097      0.707032       6.95026       7.09028   \n",
       "55109       6.81962       6.57141      0.750087       6.72339       7.06053   \n",
       "55110       6.78005       6.41808      0.853185       6.63185       6.86432   \n",
       "\n",
       "       ...  IMU_ankle_roty  IMU_ankle_rotz  IMU_ankle_magx  IMU_ankle_magy  \\\n",
       "55106  ...        0.010350       -0.053009      -88.223999       32.996899   \n",
       "55107  ...        0.040042       -0.028382      -87.089302       32.827202   \n",
       "55108  ...       -0.024165       -0.043116      -87.096298       32.838799   \n",
       "55109  ...        0.006977       -0.037264      -87.545700       32.640499   \n",
       "55110  ...        0.012983        0.010073      -87.654099       32.099201   \n",
       "\n",
       "       IMU_ankle_magz    absacc    accmax    accmin  accmaxmindiff  fftamppeak  \n",
       "55106        -4.05403  1.003447  1.048333  0.963532       0.084801    0.146737  \n",
       "55107        -2.57978  0.999723  1.048333  0.963532       0.084801    0.146762  \n",
       "55108        -3.44605  1.005541  1.048333  0.963532       0.084801    0.146781  \n",
       "55109        -3.93960  1.002116  1.048333  0.963532       0.084801    0.146793  \n",
       "55110        -4.43960  1.003846  1.048333  0.963532       0.084801    0.146798  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(r'data\\data_feats.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ensemble algorithm is demonstrated using 10 fold cross validation, a standard technique used to estimate the performance of any machine learning algorithm on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "num_trees = 100\n",
    "max_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(n_neighbors =3),\n",
    "    #\"Linear SVM\": SVC(kernel='rbf', C=1.0, gamma=0.5),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest10\": RandomForestClassifier(n_estimators=10),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \n",
    "    #Bagging Algos\n",
    "    \"Bagged Decision Trees\": BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=num_trees, random_state=seed),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=num_trees, max_features=max_features),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features),\n",
    "    #Boosting Algos\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=num_trees, random_state=seed),\n",
    "    \"Stochastic Gradient Boosting\": GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, y_col, x_cols, ratio):\n",
    "    \"\"\" \n",
    "    This method transforms a dataframe into a train and test set, for this you need to specify:\n",
    "    1. the ratio train : test (usually 0.7)\n",
    "    2. the column with the Y_values\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(len(df)) < ratio\n",
    "    df_train = df[mask]\n",
    "    df_test = df[~mask]\n",
    "       \n",
    "    Y_train = df_train[y_col].values\n",
    "    Y_test = df_test[y_col].values\n",
    "    X_train = df_train[x_cols].values\n",
    "    X_test = df_test[x_cols].values\n",
    "    return df_train, df_test, X_train, Y_train, X_test, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
    "    \"\"\"\n",
    "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
    "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
    "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
    "    is because it is very easy to save the whole dictionary with the pickle module.\n",
    "    \n",
    "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train. \n",
    "    So it is best to train them on a smaller dataset first and \n",
    "    decide whether you want to comment them out or not based on the test accuracy score.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.process_time()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.process_time()\n",
    "        t_diff = t_end - t_start\n",
    "        \n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        Y_true = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_true, Y_test)\n",
    "        \n",
    "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff, 'y_true': Y_true, 'accuracy_score': accuracy, 'y_pred': Y_test}\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
    "    return dict_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dict_models(dict_models, sort_by='test_score'):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    accuracy_s = [dict_models[key]['accuracy_score'] for key in cls]\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),5)), columns = ['classifier', 'train_score', 'test_score', 'train_time','accuracy_score'])\n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "        df_.loc[ii, 'accuracy_score'] = accuracy_s[ii]*100\n",
    "    \n",
    "    display(df_.sort_values(by=sort_by, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667592,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['activity'].values\n",
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667592, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurevector = ['accmaxmindiff','fftamppeak']\n",
    "\n",
    "features = data[featurevector].values\n",
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'activity'\n",
    "\n",
    "train_test_ratio = 0.7\n",
    "\n",
    "df_train, df_test, features_train, labels_train, features_test, labels_test = get_train_test(data, y_col, featurevector, train_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "classifier.fit(features_train, labels_train)\n",
    "train_score1 = classifier.score(features_train, labels_train)\n",
    "test_score1 = classifier.score(features_test, labels_test)\n",
    "Y_true1 = classifier.predict(features_test)\n",
    "accuracy1 = accuracy_score(Y_true1, labels_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 2.64 s\n",
      "trained Nearest Neighbors in 0.94 s\n",
      "trained Decision Tree in 2.95 s\n",
      "trained Random Forest10 in 10.16 s\n",
      "trained Neural Net in 134.00 s\n",
      "trained Naive Bayes in 0.83 s\n",
      "trained Bagged Decision Trees in 131.84 s\n",
      "trained RF in 146.53 s\n",
      "trained Extra Trees in 41.92 s\n",
      "trained AdaBoost in 93.62 s\n",
      "trained Stochastic Gradient Boosting in 226.42 s\n"
     ]
    }
   ],
   "source": [
    "dict_models = batch_classify(features_train, labels_train, features_test, labels_test, no_classifiers = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997704</td>\n",
       "      <td>41.921875</td>\n",
       "      <td>99.770372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagged Decision Trees</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>131.843750</td>\n",
       "      <td>99.699487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.996930</td>\n",
       "      <td>146.531250</td>\n",
       "      <td>99.692997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996401</td>\n",
       "      <td>2.953125</td>\n",
       "      <td>99.640083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest10</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>10.156250</td>\n",
       "      <td>99.150376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.989255</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>98.294263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stochastic Gradient Boosting</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.945738</td>\n",
       "      <td>226.421875</td>\n",
       "      <td>94.573790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.917240</td>\n",
       "      <td>0.917154</td>\n",
       "      <td>93.625000</td>\n",
       "      <td>91.715421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.915639</td>\n",
       "      <td>0.915672</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>91.567161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.875412</td>\n",
       "      <td>0.875092</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>87.509235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.850610</td>\n",
       "      <td>0.850597</td>\n",
       "      <td>2.640625</td>\n",
       "      <td>85.059703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      classifier  train_score  test_score  train_time  \\\n",
       "8                    Extra Trees     1.000000    0.997704   41.921875   \n",
       "6          Bagged Decision Trees     0.999996    0.996995  131.843750   \n",
       "7                             RF     0.999996    0.996930  146.531250   \n",
       "2                  Decision Tree     1.000000    0.996401    2.953125   \n",
       "3                Random Forest10     0.999581    0.991504   10.156250   \n",
       "1              Nearest Neighbors     0.989255    0.982943    0.937500   \n",
       "10  Stochastic Gradient Boosting     0.945783    0.945738  226.421875   \n",
       "9                       AdaBoost     0.917240    0.917154   93.625000   \n",
       "4                     Neural Net     0.915639    0.915672  134.000000   \n",
       "5                    Naive Bayes     0.875412    0.875092    0.828125   \n",
       "0            Logistic Regression     0.850610    0.850597    2.640625   \n",
       "\n",
       "    accuracy_score  \n",
       "8        99.770372  \n",
       "6        99.699487  \n",
       "7        99.692997  \n",
       "2        99.640083  \n",
       "3        99.150376  \n",
       "1        98.294263  \n",
       "10       94.573790  \n",
       "9        91.715421  \n",
       "4        91.567161  \n",
       "5        87.509235  \n",
       "0        85.059703  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_dict_models(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Store data (serialize)\n",
    "with open(r'data\\2featclass.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_models, handle)\n",
    "\n",
    "# Load data (deserialize)\n",
    "#with open('2featclass.pickle', 'rb') as handle:\n",
    " #   unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification without Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667592, 40)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = list(data.columns.values)\n",
    "unwanted = {'activity','activityID','absacc','accmin','accmax','accmaxmindiff','fftamppeak'}\n",
    "x_cols = [e for e in x_cols if e not in unwanted]\n",
    "dt = data[x_cols].values\n",
    "np.shape(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, x_train, y_train, x_test, y_test = get_train_test(data, y_col, x_cols, train_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(dt, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 557.06 s\n",
      "trained Nearest Neighbors in 4.05 s\n",
      "trained Decision Tree in 51.94 s\n",
      "trained Random Forest10 in 53.86 s\n",
      "trained Neural Net in 324.31 s\n",
      "trained Naive Bayes in 0.94 s\n",
      "trained Bagged Decision Trees in 4087.00 s\n",
      "trained RF in 201.14 s\n",
      "trained Extra Trees in 61.23 s\n",
      "trained AdaBoost in 418.14 s\n",
      "trained Stochastic Gradient Boosting in 1178.33 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>61.234375</td>\n",
       "      <td>99.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>201.140625</td>\n",
       "      <td>99.996502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>4.046875</td>\n",
       "      <td>99.992004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>53.859375</td>\n",
       "      <td>99.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stochastic Gradient Boosting</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>1178.328125</td>\n",
       "      <td>99.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagged Decision Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>4087.000000</td>\n",
       "      <td>99.961518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>51.937500</td>\n",
       "      <td>99.908544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.996616</td>\n",
       "      <td>0.996847</td>\n",
       "      <td>324.312500</td>\n",
       "      <td>99.684651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.980295</td>\n",
       "      <td>0.980869</td>\n",
       "      <td>557.062500</td>\n",
       "      <td>98.086918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.955596</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>95.559631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.741315</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>418.140625</td>\n",
       "      <td>73.913022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      classifier  train_score  test_score   train_time  \\\n",
       "8                    Extra Trees     1.000000    0.999995    61.234375   \n",
       "7                             RF     1.000000    0.999965   201.140625   \n",
       "1              Nearest Neighbors     0.999981    0.999920     4.046875   \n",
       "3                Random Forest10     1.000000    0.999885    53.859375   \n",
       "10  Stochastic Gradient Boosting     0.999940    0.999885  1178.328125   \n",
       "6          Bagged Decision Trees     1.000000    0.999615  4087.000000   \n",
       "2                  Decision Tree     1.000000    0.999085    51.937500   \n",
       "4                     Neural Net     0.996616    0.996847   324.312500   \n",
       "0            Logistic Regression     0.980295    0.980869   557.062500   \n",
       "5                    Naive Bayes     0.955801    0.955596     0.937500   \n",
       "9                       AdaBoost     0.741315    0.739130   418.140625   \n",
       "\n",
       "    accuracy_score  \n",
       "8        99.999500  \n",
       "7        99.996502  \n",
       "1        99.992004  \n",
       "3        99.988506  \n",
       "10       99.988506  \n",
       "6        99.961518  \n",
       "2        99.908544  \n",
       "4        99.684651  \n",
       "0        98.086918  \n",
       "5        95.559631  \n",
       "9        73.913022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_models1 = batch_classify(x_train, y_train, x_test, y_test, no_classifiers = 11)\n",
    "display_dict_models(dict_models1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.fit(x_train, y_train)\n",
    "#train_score = classifier.score(x_train, y_train)\n",
    "#test_score = classifier.score(x_test, y_test)\n",
    "#Y_true = classifier.predict(x_test)\n",
    "#accuracy = accuracy_score(Y_true, y_test)\n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(r'data\\class.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_models, handle)\n",
    "\n",
    "# Load data (deserialize)\n",
    "#with open('2featclass.pickle', 'rb') as handle:\n",
    " #   unserialized_data = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
