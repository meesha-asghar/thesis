{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import display \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,  AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_pickle(r'data\\data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = dt.groupby('activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just keep 4 activities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = ['standing', 'walking','running','cycling']\n",
    "data = dt.loc[dt['activity'].isin(vals)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walking     229709\n",
       "standing    188984\n",
       "cycling     163302\n",
       "running      95641\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.activity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut off first and last 1000 items, because activity starts end ends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data.activity=='running'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='running'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='walking'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='walking'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='cycling'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='cycling'].iloc[-1000:].index, inplace=True)\n",
    "data.drop(data[data.activity=='standing'].iloc[:1000].index, inplace=True)\n",
    "data.drop(data[data.activity=='standing'].iloc[-1000:].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walking     221175\n",
       "standing    181109\n",
       "cycling     151372\n",
       "running      93113\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.activity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Acceleration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "absolute acceleration: $|a|=\\sqrt{a_x^2 + a_y^2 + a_z^2}$\n",
    "\n",
    "to get rid of the orientation of the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absacc(row):\n",
    "    return np.sqrt(row['IMU_chest_ax1']**2 + row['IMU_chest_ay1']**2 + row['IMU_chest_az1']**2)/9.806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['absacc'] = data.apply(absacc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Min Difference of absolute Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=512\n",
    "dt = 1.0/100.0 # the activities were with 50Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "data['accmax'] =  data['absacc'].rolling(window=ws,center=False).max() \n",
    "data['accmin'] = data['absacc'].rolling(window=ws,center=False).min() \n",
    "\n",
    "data['accmaxmindiff'] = data.accmax - data.accmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform of Rotation Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_amplitude(s, kind='peak'):\n",
    "    \n",
    "    # don't forget the windowing to get rid of the leakage effect\n",
    "    hann = np.hanning(len(s)) \n",
    "    \n",
    "    # do the FFT with Hanning Window\n",
    "    Yhann = np.fft.fft(hann*s)\n",
    "    \n",
    "    N = int(len(Yhann)/2+1)\n",
    "    Y = 2*(np.abs(Yhann[:N])/N) # right half is enough info(positive freqs only)\n",
    "    \n",
    "    # frequency axis, if needed\n",
    "    fa = 1.0/dt\n",
    "    f = np.linspace(0, fa/2.0, N, endpoint=True)\n",
    "    \n",
    "    if kind=='peak':\n",
    "        return np.max(Y) # just return the maximum peak amplitude\n",
    "    elif kind=='periodicity':\n",
    "        return np.max(Y) / np.mean(Y) # return periodicity\n",
    "    elif kind=='full':\n",
    "        return f, Y # return the full spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['fftamppeak'] = data['IMU_chest_rotz'].rolling(window=1*ws,center=False).apply(fft_amplitude, raw=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the rolling_ functions, there is overlap between the activity features and the labels, corresponding to it. We have to delete some rows (length of window), before using a classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data.activityID==3].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==4].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==5].iloc[0:int(ws)-1].index, inplace=True)\n",
    "data.drop(data[data.activityID==6].iloc[0:int(ws)-1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activityID</th>\n",
       "      <th>activity</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>IMU_hand_temp</th>\n",
       "      <th>IMU_hand_ax1</th>\n",
       "      <th>IMU_hand_ay1</th>\n",
       "      <th>IMU_hand_az1</th>\n",
       "      <th>IMU_hand_ax2</th>\n",
       "      <th>IMU_hand_ay2</th>\n",
       "      <th>IMU_hand_az2</th>\n",
       "      <th>...</th>\n",
       "      <th>IMU_ankle_roty</th>\n",
       "      <th>IMU_ankle_rotz</th>\n",
       "      <th>IMU_ankle_magx</th>\n",
       "      <th>IMU_ankle_magy</th>\n",
       "      <th>IMU_ankle_magz</th>\n",
       "      <th>absacc</th>\n",
       "      <th>accmax</th>\n",
       "      <th>accmin</th>\n",
       "      <th>accmaxmindiff</th>\n",
       "      <th>fftamppeak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559.44</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.549558</td>\n",
       "      <td>7.35420</td>\n",
       "      <td>6.75881</td>\n",
       "      <td>0.484190</td>\n",
       "      <td>7.79716</td>\n",
       "      <td>6.62053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.053009</td>\n",
       "      <td>-88.223999</td>\n",
       "      <td>32.996899</td>\n",
       "      <td>-4.05403</td>\n",
       "      <td>1.003447</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559.45</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.513651</td>\n",
       "      <td>6.86262</td>\n",
       "      <td>6.91388</td>\n",
       "      <td>0.588009</td>\n",
       "      <td>7.32850</td>\n",
       "      <td>6.89326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040042</td>\n",
       "      <td>-0.028382</td>\n",
       "      <td>-87.089302</td>\n",
       "      <td>32.827202</td>\n",
       "      <td>-2.57978</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559.46</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.851353</td>\n",
       "      <td>6.70790</td>\n",
       "      <td>6.88097</td>\n",
       "      <td>0.707032</td>\n",
       "      <td>6.95026</td>\n",
       "      <td>7.09028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024165</td>\n",
       "      <td>-0.043116</td>\n",
       "      <td>-87.096298</td>\n",
       "      <td>32.838799</td>\n",
       "      <td>-3.44605</td>\n",
       "      <td>1.005541</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559.47</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.765876</td>\n",
       "      <td>6.81962</td>\n",
       "      <td>6.57141</td>\n",
       "      <td>0.750087</td>\n",
       "      <td>6.72339</td>\n",
       "      <td>7.06053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>-0.037264</td>\n",
       "      <td>-87.545700</td>\n",
       "      <td>32.640499</td>\n",
       "      <td>-3.93960</td>\n",
       "      <td>1.002116</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559.48</th>\n",
       "      <td>3</td>\n",
       "      <td>standing</td>\n",
       "      <td>101</td>\n",
       "      <td>32.6875</td>\n",
       "      <td>0.798051</td>\n",
       "      <td>6.78005</td>\n",
       "      <td>6.41808</td>\n",
       "      <td>0.853185</td>\n",
       "      <td>6.63185</td>\n",
       "      <td>6.86432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>-87.654099</td>\n",
       "      <td>32.099201</td>\n",
       "      <td>-4.43960</td>\n",
       "      <td>1.003846</td>\n",
       "      <td>1.048333</td>\n",
       "      <td>0.963532</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>0.146798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           activityID  activity  heartrate  IMU_hand_temp  IMU_hand_ax1  \\\n",
       "timestamp                                                                 \n",
       "559.44              3  standing        101        32.6875      0.549558   \n",
       "559.45              3  standing        101        32.6875      0.513651   \n",
       "559.46              3  standing        101        32.6875      0.851353   \n",
       "559.47              3  standing        101        32.6875      0.765876   \n",
       "559.48              3  standing        101        32.6875      0.798051   \n",
       "\n",
       "           IMU_hand_ay1  IMU_hand_az1  IMU_hand_ax2  IMU_hand_ay2  \\\n",
       "timestamp                                                           \n",
       "559.44          7.35420       6.75881      0.484190       7.79716   \n",
       "559.45          6.86262       6.91388      0.588009       7.32850   \n",
       "559.46          6.70790       6.88097      0.707032       6.95026   \n",
       "559.47          6.81962       6.57141      0.750087       6.72339   \n",
       "559.48          6.78005       6.41808      0.853185       6.63185   \n",
       "\n",
       "           IMU_hand_az2  ...  IMU_ankle_roty  IMU_ankle_rotz  IMU_ankle_magx  \\\n",
       "timestamp                ...                                                   \n",
       "559.44          6.62053  ...        0.010350       -0.053009      -88.223999   \n",
       "559.45          6.89326  ...        0.040042       -0.028382      -87.089302   \n",
       "559.46          7.09028  ...       -0.024165       -0.043116      -87.096298   \n",
       "559.47          7.06053  ...        0.006977       -0.037264      -87.545700   \n",
       "559.48          6.86432  ...        0.012983        0.010073      -87.654099   \n",
       "\n",
       "           IMU_ankle_magy  IMU_ankle_magz    absacc    accmax    accmin  \\\n",
       "timestamp                                                                 \n",
       "559.44          32.996899        -4.05403  1.003447  1.048333  0.963532   \n",
       "559.45          32.827202        -2.57978  0.999723  1.048333  0.963532   \n",
       "559.46          32.838799        -3.44605  1.005541  1.048333  0.963532   \n",
       "559.47          32.640499        -3.93960  1.002116  1.048333  0.963532   \n",
       "559.48          32.099201        -4.43960  1.003846  1.048333  0.963532   \n",
       "\n",
       "           accmaxmindiff  fftamppeak  \n",
       "timestamp                             \n",
       "559.44          0.084801    0.146737  \n",
       "559.45          0.084801    0.146762  \n",
       "559.46          0.084801    0.146781  \n",
       "559.47          0.084801    0.146793  \n",
       "559.48          0.084801    0.146798  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(r'data\\data_feats.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each ensemble algorithm is demonstrated using 10 fold cross validation, a standard technique used to estimate the performance of any machine learning algorithm on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "num_trees = 100\n",
    "max_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(n_neighbors =3),\n",
    "    #\"Linear SVM\": SVC(kernel='rbf', C=1.0, gamma=0.5),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest10\": RandomForestClassifier(n_estimators=10),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \n",
    "    #Bagging Algos\n",
    "    \"Bagged Decision Trees\": BaggingClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=num_trees, random_state=seed),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=num_trees, max_features=max_features),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features),\n",
    "    #Boosting Algos\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=num_trees, random_state=seed),\n",
    "    #Stochastic Gradient Boosting\n",
    "    \"Stochastic Gradient Boosting\": GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
    "    \"\"\"\n",
    "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
    "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
    "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
    "    is because it is very easy to save the whole dictionary with the pickle module.\n",
    "    \n",
    "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train. \n",
    "    So it is best to train them on a smaller dataset first and \n",
    "    decide whether you want to comment them out or not based on the test accuracy score.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.process_time()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.process_time()\n",
    "        t_diff = t_end - t_start\n",
    "        \n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        Y_true = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_true, Y_test)\n",
    "        \n",
    "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff, 'y_true': Y_true, 'accuracy_score': accuracy, 'y_pred': Y_test}\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
    "    return dict_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dict_models(dict_models, sort_by='test_score'):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    accuracy_s = [dict_models[key]['accuracy_score'] for key in cls]\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),5)), columns = ['classifier', 'train_score', 'test_score', 'train_time','accuracy_score'])\n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "        df_.loc[ii, 'accuracy_score'] = accuracy_s[ii]*100\n",
    "    \n",
    "    display(df_.sort_values(by=sort_by, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638707,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['activity'].values\n",
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638707, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurevector = ['accmaxmindiff','fftamppeak']\n",
    "\n",
    "features = data[featurevector].values\n",
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 3.91 s\n",
      "trained Nearest Neighbors in 0.83 s\n",
      "trained Decision Tree in 2.19 s\n",
      "trained Random Forest10 in 11.55 s\n",
      "trained Neural Net in 136.89 s\n",
      "trained Naive Bayes in 0.89 s\n",
      "trained Bagged Decision Trees in 142.30 s\n",
      "trained RF in 141.56 s\n",
      "trained Extra Trees in 51.17 s\n",
      "trained AdaBoost in 95.30 s\n",
      "trained Stochastic Gradient Boosting in 266.64 s\n"
     ]
    }
   ],
   "source": [
    "dict_models = batch_classify(features_train, labels_train, features_test, labels_test, no_classifiers = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>51.171875</td>\n",
       "      <td>99.746754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagged Decision Trees</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.996329</td>\n",
       "      <td>142.296875</td>\n",
       "      <td>99.632852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.996285</td>\n",
       "      <td>141.562500</td>\n",
       "      <td>99.628547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>99.559658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest10</td>\n",
       "      <td>0.999559</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>11.546875</td>\n",
       "      <td>99.135363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.989356</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>98.086370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stochastic Gradient Boosting</td>\n",
       "      <td>0.946126</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>266.640625</td>\n",
       "      <td>94.495916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.921605</td>\n",
       "      <td>0.920652</td>\n",
       "      <td>95.296875</td>\n",
       "      <td>92.065225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.917200</td>\n",
       "      <td>0.916061</td>\n",
       "      <td>136.890625</td>\n",
       "      <td>91.606095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.878575</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>87.785097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.856363</td>\n",
       "      <td>0.855576</td>\n",
       "      <td>3.906250</td>\n",
       "      <td>85.557552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      classifier  train_score  test_score  train_time  \\\n",
       "8                    Extra Trees     1.000000    0.997468   51.171875   \n",
       "6          Bagged Decision Trees     0.999997    0.996329  142.296875   \n",
       "7                             RF     0.999995    0.996285  141.562500   \n",
       "2                  Decision Tree     1.000000    0.995597    2.187500   \n",
       "3                Random Forest10     0.999559    0.991354   11.546875   \n",
       "1              Nearest Neighbors     0.989356    0.980864    0.828125   \n",
       "10  Stochastic Gradient Boosting     0.946126    0.944959  266.640625   \n",
       "9                       AdaBoost     0.921605    0.920652   95.296875   \n",
       "4                     Neural Net     0.917200    0.916061  136.890625   \n",
       "5                    Naive Bayes     0.878575    0.877851    0.890625   \n",
       "0            Logistic Regression     0.856363    0.855576    3.906250   \n",
       "\n",
       "    accuracy_score  \n",
       "8        99.746754  \n",
       "6        99.632852  \n",
       "7        99.628547  \n",
       "2        99.559658  \n",
       "3        99.135363  \n",
       "1        98.086370  \n",
       "10       94.495916  \n",
       "9        92.065225  \n",
       "4        91.606095  \n",
       "5        87.785097  \n",
       "0        85.557552  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_dict_models(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Store data (serialize)\n",
    "with open(r'data\\2featclass.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_models, handle)\n",
    "\n",
    "# Load data (deserialize)\n",
    "#with open('2featclass.pickle', 'rb') as handle:\n",
    " #   unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification without Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638707, 40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = list(data.columns.values)\n",
    "unwanted = {'activity','activityID','absacc','accmin','accmax','accmaxmindiff','fftamppeak'}\n",
    "x_cols = [e for e in x_cols if e not in unwanted]\n",
    "dt = data[x_cols].values\n",
    "np.shape(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(dt, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\meesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 649.08 s\n",
      "trained Nearest Neighbors in 3.31 s\n",
      "trained Decision Tree in 51.70 s\n",
      "trained Random Forest10 in 62.73 s\n",
      "trained Neural Net in 186.23 s\n",
      "trained Naive Bayes in 1.22 s\n",
      "trained Bagged Decision Trees in 3606.72 s\n",
      "trained RF in 216.06 s\n",
      "trained Extra Trees in 80.28 s\n",
      "trained AdaBoost in 426.55 s\n",
      "trained Stochastic Gradient Boosting in 1602.39 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>80.281250</td>\n",
       "      <td>99.999609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>99.993737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stochastic Gradient Boosting</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>1602.390625</td>\n",
       "      <td>99.989823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>216.062500</td>\n",
       "      <td>99.987475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest10</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>62.734375</td>\n",
       "      <td>99.984735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagged Decision Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>3606.718750</td>\n",
       "      <td>99.965555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>51.703125</td>\n",
       "      <td>99.924065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.996430</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>186.234375</td>\n",
       "      <td>99.626981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.981267</td>\n",
       "      <td>0.980457</td>\n",
       "      <td>649.078125</td>\n",
       "      <td>98.045663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>1.218750</td>\n",
       "      <td>95.595402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.874752</td>\n",
       "      <td>0.874387</td>\n",
       "      <td>426.546875</td>\n",
       "      <td>87.438695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      classifier  train_score  test_score   train_time  \\\n",
       "8                    Extra Trees     1.000000    0.999996    80.281250   \n",
       "1              Nearest Neighbors     0.999961    0.999937     3.312500   \n",
       "10  Stochastic Gradient Boosting     0.999948    0.999898  1602.390625   \n",
       "7                             RF     1.000000    0.999875   216.062500   \n",
       "3                Random Forest10     0.999997    0.999847    62.734375   \n",
       "6          Bagged Decision Trees     1.000000    0.999656  3606.718750   \n",
       "2                  Decision Tree     1.000000    0.999241    51.703125   \n",
       "4                     Neural Net     0.996430    0.996270   186.234375   \n",
       "0            Logistic Regression     0.981267    0.980457   649.078125   \n",
       "5                    Naive Bayes     0.955694    0.955954     1.218750   \n",
       "9                       AdaBoost     0.874752    0.874387   426.546875   \n",
       "\n",
       "    accuracy_score  \n",
       "8        99.999609  \n",
       "1        99.993737  \n",
       "10       99.989823  \n",
       "7        99.987475  \n",
       "3        99.984735  \n",
       "6        99.965555  \n",
       "2        99.924065  \n",
       "4        99.626981  \n",
       "0        98.045663  \n",
       "5        95.595402  \n",
       "9        87.438695  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_models1 = batch_classify(df_train, y_train, df_test, y_test, no_classifiers = 11)\n",
    "display_dict_models(dict_models1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open(r'data\\class.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_models, handle)\n",
    "\n",
    "# Load data (deserialize)\n",
    "#with open('2featclass.pickle', 'rb') as handle:\n",
    " #   unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
